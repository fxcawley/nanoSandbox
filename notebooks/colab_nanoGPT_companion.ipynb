{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# nanoGPT Colab companion (single-VM demo)\n",
        "\n",
        "This notebook mirrors the nanoGPT training used in the Kubernetes project but runs inside a single VM (Colab) with up to 1 GPU. It helps you validate configs quickly before you run the Kubernetes jobs on your GPU server.\n",
        "\n",
        "What you will learn:\n",
        "- Install nanoGPT and minimal deps\n",
        "- Prepare tiny Shakespeare dataset\n",
        "- Run CPU-only quick check\n",
        "- If GPU is available, run `torchrun --standalone --nproc_per_node=2` to simulate multi-process training on a single VM\n",
        "\n",
        "Note: This does not use Kubernetes, PV/PVC, or multi-pod networking. See the repo README for Kubernetes steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "!nvidia-smi -L || echo \"No GPU detected\"\n",
        "\n",
        "import sys, subprocess\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    print(\"Installing:\", pkgs)\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\"] + pkgs)\n",
        "\n",
        "pip_install([\"torch==2.3.1\", \"torchaudio==2.3.1\", \"torchvision==0.18.1\", \"--index-url\", \"https://download.pytorch.org/whl/cu118\"])\n",
        "pip_install([\"tiktoken\", \"numpy\", \"tensorboard\"])\n",
        "\n",
        "!git clone https://github.com/karpathy/nanoGPT.git /content/nanogpt || true\n",
        "%cd /content/nanogpt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare tiny Shakespeare dataset\n",
        "%cd /content/nanogpt/data/shakespeare_char\n",
        "!python prepare.py\n",
        "\n",
        "# Move prepared data to a known path for training\n",
        "!mkdir -p /content/data/datasets/shakespeare_char\n",
        "!cp -v train.bin val.bin meta.pkl /content/data/datasets/shakespeare_char/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CPU-only smoke test (fast)\n",
        "%cd /content/nanogpt\n",
        "!python - <<'PY'\n",
        "import os, subprocess\n",
        "cmd = [\n",
        "    'python','train.py','config/train_shakespeare_char.py',\n",
        "    '--out_dir=/content/runs/cpu',\n",
        "    '--eval_interval=50','--log_interval=1',\n",
        "    '--block_size=128','--batch_size=16',\n",
        "    '--n_layer=2','--n_head=2','--n_embd=64',\n",
        "    '--max_iters=50','--lr_decay_iters=50','--dropout=0.0',\n",
        "    '--device=cpu','--compile=False',\n",
        "    '--dataset=shakespeare_char'\n",
        "]\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.check_call(cmd)\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: 2-process torchrun on one VM (if GPU available)\n",
        "%cd /content/nanogpt\n",
        "!python - <<'PY'\n",
        "import os, shutil, subprocess, sys\n",
        "\n",
        "def has_gpu():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi','-L'], stderr=subprocess.STDOUT)\n",
        "        return b'GPU' in out\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "if not has_gpu():\n",
        "    print('No GPU available, skipping torchrun demo')\n",
        "    sys.exit(0)\n",
        "\n",
        "cmd = [\n",
        "    'torchrun','--standalone','--nproc_per_node=2','train.py','config/train_shakespeare_char.py',\n",
        "    '--out_dir=/content/runs/torchrun',\n",
        "    '--eval_interval=50','--log_interval=1',\n",
        "    '--block_size=128','--batch_size=16',\n",
        "    '--n_layer=2','--n_head=2','--n_embd=64',\n",
        "    '--max_iters=100','--lr_decay_iters=100','--dropout=0.0',\n",
        "    '--device=cuda','--compile=False',\n",
        "    '--dataset=shakespeare_char'\n",
        "]\n",
        "print('Running:', ' '.join(cmd))\n",
        "subprocess.check_call(cmd)\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- Logs are written under `/content/runs`. Use TensorBoard from the left sidebar (Colab) or `%load_ext tensorboard` and `%tensorboard --logdir /content/runs`.\n",
        "- For Kubernetes runs, the datasets and runs live under the PVC mount (`/data`). This notebook mirrors the configs but not the storage/networking model.\n",
        "- Map to Kubernetes:\n",
        "  - `torchrun --standalone --nproc_per_node=2` â‰ˆ single-Pod multi-GPU with `nproc_per_node=2`\n",
        "  - Multi-pod DDP in Kubernetes uses `--nnodes` `--node_rank` and headless Service rendezvous; not demonstrated here.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
